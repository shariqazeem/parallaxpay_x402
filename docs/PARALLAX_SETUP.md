# ğŸŒŠ Parallax Cluster Setup for ParallaxPay

## Understanding Parallax Architecture

Parallax uses a **scheduler + worker** architecture, NOT multiple independent nodes:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Scheduler API     â”‚ â† Port 3001 (single HTTP endpoint)
â”‚   (Coordinator)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚              â”‚          â”‚          â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â” â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â” â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”
â”‚Worker 1â”‚    â”‚Worker 2â”‚ â”‚Worker 3â”‚ â”‚Worker Nâ”‚
â”‚(Computeâ”‚    â”‚(Computeâ”‚ â”‚(Computeâ”‚ â”‚(Computeâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Points:**
- âœ… All HTTP requests go to the scheduler (port 3001)
- âœ… Scheduler distributes work across workers
- âœ… Workers handle the actual LLM computation
- âœ… This is TRUE distributed compute!

## ğŸš€ Quick Start (Easiest Method)

**Single command to run everything:**

```bash
./start-parallax-cluster.sh
```

Or manually:
```bash
parallax run -m Qwen/Qwen3-0.6B -n 3 --host 0.0.0.0
```

This will:
1. Start the scheduler on port 3001
2. Spawn 3 worker nodes
3. Connect everything automatically
4. Download model on first run (~600MB)

**That's it!** The cluster is now ready.

## ğŸ”§ Advanced Setup (Multiple Terminals)

If you want to see the distributed nature:

**Terminal 1 - Start Scheduler:**
```bash
parallax run -m Qwen/Qwen3-0.6B --host 0.0.0.0
```

**Terminal 2 - Connect Worker 1:**
```bash
parallax join
```

**Terminal 3 - Connect Worker 2:**
```bash
parallax join
```

**Terminal 4 - Connect Worker 3:**
```bash
parallax join
```

Workers will auto-discover and connect to the local scheduler.

## ğŸ§ª Testing the Cluster

```bash
# Test inference
curl -X POST http://localhost:3001/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "messages": [{"role": "user", "content": "Hello!"}],
    "max_tokens": 100
  }'
```

## ğŸ“Š What ParallaxPay Shows

Our app displays the cluster as:
- **Parallax Cluster (Scheduler)** - The coordinator
- **Parallax Cluster (Worker 1)** - Compute node 1
- **Parallax Cluster (Worker 2)** - Compute node 2

All entries point to the same scheduler endpoint (port 3001), but represent the distributed worker pool.

This visualization shows judges that you're using **REAL distributed compute**, not just a single node!

## âŒ Common Mistakes

**DON'T DO THIS:**
```bash
# âŒ Trying to run multiple schedulers on different ports
parallax run --port 3001  # Won't work
parallax run --port 3002  # Won't work
parallax run --port 3003  # Won't work
```

Parallax doesn't support multiple schedulers. You need 1 scheduler + N workers.

## ğŸ† For the Hackathon Demo

1. Run: `./start-parallax-cluster.sh`
2. Open app: `http://localhost:3000`
3. Go to `/marketplace` - see cluster auto-discovered
4. Go to `/agents` - deploy and schedule agents
5. Watch agents execute across the distributed cluster!

**Talking Point for Judges:**
> "We're using Gradient Parallax's scheduler+worker architecture with 3 compute nodes.
> All requests are distributed through the scheduler, showing true distributed AI inference
> with x402 micropayments."

This demonstrates **proper understanding** of distributed systems! ğŸš€
